{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script goes along my blog post:\n",
    "Keras Cats Dogs Tutorial (https://jkjung-avt.github.io/keras-tutorial/)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.python.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "DATASET_PATH  = './catsdogs/sample'\n",
    "IMAGE_SIZE    = (224, 224)\n",
    "NUM_CLASSES   = 2\n",
    "BATCH_SIZE    = 8  # try reducing batch size or freeze more layers if your GPU runs out of memory\n",
    "FREEZE_LAYERS = 2  # freeze the first this many layers for training\n",
    "NUM_EPOCHS    = 20\n",
    "WEIGHTS_FINAL = 'model-resnet50-final.h5'\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   channel_shift_range=10,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "train_batches = train_datagen.flow_from_directory(DATASET_PATH + '/train',\n",
    "                                                  target_size=IMAGE_SIZE,\n",
    "                                                  interpolation='bicubic',\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=True,\n",
    "                                                  batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "valid_batches = valid_datagen.flow_from_directory(DATASET_PATH + '/valid',\n",
    "                                                  target_size=IMAGE_SIZE,\n",
    "                                                  interpolation='bicubic',\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=False,\n",
    "                                                  batch_size=BATCH_SIZE)\n",
    "\n",
    "# show class indices\n",
    "print('****************')\n",
    "for cls, idx in train_batches.class_indices.items():\n",
    "    print('Class #{} = {}'.format(idx, cls))\n",
    "print('****************')\n",
    "\n",
    "# build our classifier model based on pre-trained ResNet50:\n",
    "# 1. we don't include the top (fully connected) layers of ResNet50\n",
    "# 2. we add a DropOut layer followed by a Dense (fully connected)\n",
    "#    layer which generates softmax class score for each class\n",
    "# 3. we compile the final model using an Adam optimizer, with a\n",
    "#    low learning rate (since we are 'fine-tuning')\n",
    "net = ResNet50(include_top=False, weights='imagenet', input_tensor=None,\n",
    "               input_shape=(IMAGE_SIZE[0],IMAGE_SIZE[1],3))\n",
    "x = net.output\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output_layer = Dense(NUM_CLASSES, activation='softmax', name='softmax')(x)\n",
    "net_final = Model(inputs=net.input, outputs=output_layer)\n",
    "for layer in net_final.layers[:FREEZE_LAYERS]:\n",
    "    layer.trainable = False\n",
    "for layer in net_final.layers[FREEZE_LAYERS:]:\n",
    "    layer.trainable = True\n",
    "net_final.compile(optimizer=Adam(lr=1e-5),\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(net_final.summary())\n",
    "\n",
    "# train the model\n",
    "net_final.fit_generator(train_batches,\n",
    "                        steps_per_epoch = train_batches.samples // BATCH_SIZE,\n",
    "                        validation_data = valid_batches,\n",
    "                        validation_steps = valid_batches.samples // BATCH_SIZE,\n",
    "                        epochs = NUM_EPOCHS)\n",
    "\n",
    "# save trained weights\n",
    "net_final.save(WEIGHTS_FINAL)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
